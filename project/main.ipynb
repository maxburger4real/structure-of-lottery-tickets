{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import symbolic_1\n",
    "\n",
    "from architectures.simlpe_mlp import SimpleMLP\n",
    "\n",
    "import iterative_magnitude_pruning_with_reinit\n",
    "\n",
    "from common.torch_utils import remaining_weights_by_pruning_steps\n",
    "from common.training import build_optimizer\n",
    "from common.tracking import Config, SGD, ADAM, PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    experiment = 'basic-test',\n",
    "    lr = 0.001,\n",
    "    dataset = symbolic_1.DATASET_NAME,\n",
    "    training_epochs = 10,\n",
    "    pruning_levels = 10,\n",
    "    pruning_rate   = 1,\n",
    "    num_layers   = 'num_layers',\n",
    "    prune_weights = True,\n",
    "    prune_biases = False,\n",
    "    pruning_strategy= 'global',\n",
    "    model_shape = [symbolic_1.INPUT_DIM, 20, 20, symbolic_1.OUTPUT_DIM],\n",
    "    optimizer=SGD,\n",
    "    momentum=0,\n",
    "    model_seed=1,\n",
    "    data_seed=1,\n",
    "    batch_size = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = SimpleMLP(config.model_shape, seed = config.model_seed)\n",
    "config.architecture = model.name\n",
    "\n",
    "remaining_weights_by_pruning_steps(\n",
    "    model, \n",
    "    config.pruning_rate, \n",
    "    config.pruning_levels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optim = build_optimizer(model, config)\n",
    "\n",
    "# loss function and dataloaders\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "train_loader, test_loader = symbolic_1.get_dataloaders(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "with wandb.init(project=PROJECT, name=config.experiment, config=config):\n",
    "    model = iterative_magnitude_pruning_with_reinit.run(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        optim=optim,\n",
    "        loss_fn=loss_fn,\n",
    "        config=config,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
