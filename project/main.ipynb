{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import os\n",
    "# os.environ[\"WANDB_MODE\"]=\"offline\"\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from training_pipelines import regular, single_shot_pruning\n",
    "\n",
    "from common.architectures import SimpleMLP\n",
    "from common.datasets import symbolic_1\n",
    "from common.tracking import Config, SGD, ADAM, PROJECT, save_hparams\n",
    "from common.training import build_optimizer\n",
    "i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelClass = SimpleMLP\n",
    "config = Config(\n",
    "    experiment=f'IMP-reinit {i}',\n",
    "    dataset=symbolic_1.DATASET_NAME,\n",
    "    model_shape=[symbolic_1.INPUT_DIM, 20, 20, symbolic_1.OUTPUT_DIM],\n",
    "    model_class = ModelClass.__name__,\n",
    "\n",
    "    # pruning\n",
    "    pruning_levels=30,\n",
    "    pruning_rate=0.1,\n",
    "    pruning_strategy='global',\n",
    "    prune_weights=True,\n",
    "    prune_biases=False,\n",
    "\n",
    "    # training\n",
    "    training_epochs=1500,\n",
    "    lr=0.001,\n",
    "    momentum=0,\n",
    "    optimizer=ADAM,\n",
    "    batch_size = None,\n",
    "\n",
    "    # seeds\n",
    "    model_seed=2,\n",
    "    data_seed=2,\n",
    "\n",
    "    # lottery\n",
    "    reinit=True,\n",
    "\n",
    "    # storage\n",
    "    persist=True,\n",
    "    timestamp=datetime.now().strftime(\"%Y_%m_%d_%H%M%S\"),\n",
    ")\n",
    "\n",
    "# create the model\n",
    "model = ModelClass(config.model_shape, seed=config.model_seed)\n",
    "optim = build_optimizer(model, config)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# dataloaders\n",
    "train_loader, test_loader = symbolic_1.get_dataloaders(config.batch_size)\n",
    "\n",
    "save_hparams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/max/Documents/JKU/_Master_Thesis/project/wandb/run-20231003_144009-04ew13rn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mxmn/init-thesis/runs/04ew13rn' target=\"_blank\">IMP-reinit 1</a></strong> to <a href='https://wandb.ai/mxmn/init-thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mxmn/init-thesis' target=\"_blank\">https://wandb.ai/mxmn/init-thesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mxmn/init-thesis/runs/04ew13rn' target=\"_blank\">https://wandb.ai/mxmn/init-thesis/runs/04ew13rn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▃▁▆▄▄▂▇▄▅▂▇▇▅▃██▆▃▃▁▆▄▄▂▇▇▅▂▇▇▅▃▃█▆▃▃▁▆▆</td></tr><tr><td>loss/eval/0.00</td><td>█▇▆▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.10</td><td>█▆▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.20</td><td>█▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.28</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.36</td><td>█▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.43</td><td>█▅▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.49</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.54</td><td>█▅▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.59</td><td>█▆▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.64</td><td>█▆▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.67</td><td>█▇▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.71</td><td>█▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.74</td><td>█▇▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.77</td><td>█▇▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.80</td><td>█▇▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.82</td><td>█▇▅▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.83</td><td>█▇▅▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.85</td><td>█▇▆▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.87</td><td>██▇▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.88</td><td>██▇▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.90</td><td>██▇▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.91</td><td>█▇▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.92</td><td>██▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.93</td><td>██▇▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.94</td><td>███▇▆▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.95</td><td>██▇▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁██▇▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>loss/eval/0.96</td><td>██▇▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁██▇▅▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/eval/0.97</td><td>████▇▇▆▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/evalinit</td><td>▁</td></tr><tr><td>loss/train/0.00</td><td>█▇▆▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.10</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.20</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.28</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.36</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.43</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.49</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.54</td><td>█▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.59</td><td>█▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.64</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.67</td><td>█▆▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.71</td><td>█▆▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.74</td><td>█▇▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.77</td><td>█▇▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.80</td><td>█▇▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.82</td><td>█▇▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.83</td><td>█▇▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.85</td><td>█▇▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.87</td><td>█▇▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.88</td><td>██▇▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.90</td><td>██▇▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.91</td><td>█▇▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▇▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.92</td><td>██▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.93</td><td>██▇▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.94</td><td>███▇▆▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.95</td><td>██▇▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁██▇▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>loss/train/0.96</td><td>██▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁██▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/train/0.97</td><td>████▇▇▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nonzero</td><td>█▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>p-lvl</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>sparsity</td><td>▁▂▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1500</td></tr><tr><td>loss/eval/0.00</td><td>0.09218</td></tr><tr><td>loss/eval/0.10</td><td>0.08529</td></tr><tr><td>loss/eval/0.20</td><td>0.09015</td></tr><tr><td>loss/eval/0.28</td><td>0.10328</td></tr><tr><td>loss/eval/0.36</td><td>0.09804</td></tr><tr><td>loss/eval/0.43</td><td>0.1085</td></tr><tr><td>loss/eval/0.49</td><td>0.10798</td></tr><tr><td>loss/eval/0.54</td><td>0.08402</td></tr><tr><td>loss/eval/0.59</td><td>0.07163</td></tr><tr><td>loss/eval/0.64</td><td>0.07356</td></tr><tr><td>loss/eval/0.67</td><td>0.08353</td></tr><tr><td>loss/eval/0.71</td><td>0.10281</td></tr><tr><td>loss/eval/0.74</td><td>0.088</td></tr><tr><td>loss/eval/0.77</td><td>0.09991</td></tr><tr><td>loss/eval/0.80</td><td>0.09179</td></tr><tr><td>loss/eval/0.82</td><td>0.08351</td></tr><tr><td>loss/eval/0.83</td><td>0.0741</td></tr><tr><td>loss/eval/0.85</td><td>0.07399</td></tr><tr><td>loss/eval/0.87</td><td>0.09059</td></tr><tr><td>loss/eval/0.88</td><td>0.06872</td></tr><tr><td>loss/eval/0.90</td><td>0.19343</td></tr><tr><td>loss/eval/0.91</td><td>0.20499</td></tr><tr><td>loss/eval/0.92</td><td>0.31585</td></tr><tr><td>loss/eval/0.93</td><td>0.32715</td></tr><tr><td>loss/eval/0.94</td><td>0.32771</td></tr><tr><td>loss/eval/0.95</td><td>0.50722</td></tr><tr><td>loss/eval/0.96</td><td>0.51031</td></tr><tr><td>loss/eval/0.97</td><td>0.51082</td></tr><tr><td>loss/evalinit</td><td>1.69188</td></tr><tr><td>loss/train/0.00</td><td>0.00438</td></tr><tr><td>loss/train/0.10</td><td>0.00346</td></tr><tr><td>loss/train/0.20</td><td>0.00607</td></tr><tr><td>loss/train/0.28</td><td>0.00456</td></tr><tr><td>loss/train/0.36</td><td>0.00514</td></tr><tr><td>loss/train/0.43</td><td>0.00649</td></tr><tr><td>loss/train/0.49</td><td>0.00667</td></tr><tr><td>loss/train/0.54</td><td>0.00591</td></tr><tr><td>loss/train/0.59</td><td>0.00594</td></tr><tr><td>loss/train/0.64</td><td>0.00607</td></tr><tr><td>loss/train/0.67</td><td>0.00691</td></tr><tr><td>loss/train/0.71</td><td>0.00719</td></tr><tr><td>loss/train/0.74</td><td>0.00744</td></tr><tr><td>loss/train/0.77</td><td>0.00736</td></tr><tr><td>loss/train/0.80</td><td>0.00733</td></tr><tr><td>loss/train/0.82</td><td>0.00792</td></tr><tr><td>loss/train/0.83</td><td>0.01509</td></tr><tr><td>loss/train/0.85</td><td>0.01557</td></tr><tr><td>loss/train/0.87</td><td>0.01374</td></tr><tr><td>loss/train/0.88</td><td>0.01397</td></tr><tr><td>loss/train/0.90</td><td>0.08893</td></tr><tr><td>loss/train/0.91</td><td>0.09326</td></tr><tr><td>loss/train/0.92</td><td>0.13933</td></tr><tr><td>loss/train/0.93</td><td>0.14683</td></tr><tr><td>loss/train/0.94</td><td>0.14694</td></tr><tr><td>loss/train/0.95</td><td>0.28413</td></tr><tr><td>loss/train/0.96</td><td>0.28466</td></tr><tr><td>loss/train/0.97</td><td>0.28469</td></tr><tr><td>nonzero</td><td>18</td></tr><tr><td>p-lvl</td><td>31</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">IMP-reinit 1</strong> at: <a href='https://wandb.ai/mxmn/init-thesis/runs/04ew13rn' target=\"_blank\">https://wandb.ai/mxmn/init-thesis/runs/04ew13rn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231003_144009-04ew13rn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# run the experiment\n",
    "with wandb.init(project=PROJECT, name=config.experiment, config=config):\n",
    "    model = single_shot_pruning.run(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        optim=optim,\n",
    "        loss_fn=loss_fn,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
