{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import symbolic_1\n",
    "from architectures.bio_mlp import BioMLP\n",
    "\n",
    "from common import STATE_DICT\n",
    "\n",
    "import pathlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL BIMT HYPERPARAMETERS\n",
    "shp = [symbolic_1.INPUT_DIM, 20, 20, symbolic_1.OUTPUT_DIM]\n",
    "model = BioMLP(shp=shp)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0)\n",
    "log = 200\n",
    "lamb = 0.001\n",
    "dump_every = 200\n",
    "swap_log = 200\n",
    "weight_factor = 1.\n",
    "plot_log = 50\n",
    "epochs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL BIMT HYPERPARAMETERS\n",
    "shp = [symbolic_1.INPUT_DIM, 20, 20, symbolic_1.OUTPUT_DIM]\n",
    "model = BioMLP(shp=shp)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=0.0)\n",
    "log = 200\n",
    "lamb = 0.001\n",
    "dump_every = 50\n",
    "swap_log = 200\n",
    "weight_factor = 1.\n",
    "plot_log = 50\n",
    "epochs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done in the save method\n",
    "\n",
    "name = BioMLP.__name__ + str(shp).replace(', ','_').replace('[','_').replace(']','')\n",
    "base = pathlib.Path(\"models\") / name / datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "base.mkdir(parents=True, exist_ok=True)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = symbolic_1.get_dataloaders()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    if step == int(epochs/4):\n",
    "        lamb *= 10\n",
    "    \n",
    "    if step == int(3*epochs/4):\n",
    "        lamb *= 0.1\n",
    "\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        pred_test  = model(x)\n",
    "        loss_test = torch.mean((pred_test-y)**2)\n",
    "        \n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pred  = model(x)\n",
    "        loss = torch.mean((pred-y)**2)\n",
    "\n",
    "        # do not penalize bias at first (this makes the weight graph look better)\n",
    "        training_in_last_quarter = step > int(3*epochs/4)\n",
    "        penalize = True if training_in_last_quarter else False\n",
    "        reg = model.get_cc(bias_penalize=penalize, weight_factor=weight_factor)\n",
    "\n",
    "        #reg = model.get_cc(bias_penalize=True)\n",
    "        total_loss = loss + lamb*reg\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if step % log == 0:\n",
    "        print(\"step = %d | total loss: %.2e | train loss: %.2e | test loss %.2e | reg: %.2e \"%(step, total_loss.detach().numpy(), loss.detach().numpy(), loss_test.detach().numpy(), reg.detach().numpy()))\n",
    "    \n",
    "    if step % swap_log == 0:\n",
    "    #if (step+1) % swap_log == 0:\n",
    "        # TODO: this results in large weights for one epoch. WHY?\n",
    "        model.relocate()\n",
    "\n",
    "    if step % dump_every == 0:\n",
    "        torch.save({\n",
    "                'epoch': step,\n",
    "                STATE_DICT: model.state_dict(),\n",
    "                # 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': loss.item(),\n",
    "                'test_loss': loss_test.item(),\n",
    "                }, base / f\"{step}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from common.nx_utils import( \n",
    "    get_weights_from_state_dict, \n",
    "    load_state_dict, \n",
    "    get_shape_from_state_dict,\n",
    "    add_neuron_nodes,\n",
    "    black_and_white,\n",
    "    add_weight_edges_arrays,\n",
    "    get_layers_of_nodes,\n",
    "    layerwise_normalized_abs_value\n",
    ")\n",
    "from common.bokeh_utils import (\n",
    "    draw_interactive_mlp_graph,\n",
    "    LINE_COLOR_LIST,\n",
    "    LINE_WIDTH_LIST\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "base = pathlib.Path(\"models/BioMLP_4_20_20_2/2023-09-20_112428\")\n",
    "chkpts = list(base.glob(\"*.pt\"))\n",
    "sort_by_integer_in_filename_key = lambda x : int(*re.findall(\"(\\d+)\",x.name))\n",
    "sorted_chkpts = sorted(chkpts, key=sort_by_integer_in_filename_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = load_state_dict(chkpts[0])\n",
    "weight_shapes = get_shape_from_state_dict(state_dict)\n",
    "\n",
    "# retrieve weights from state_dicts\n",
    "state_dicts = [load_state_dict(f) for f in sorted_chkpts]\n",
    "weights = [get_weights_from_state_dict(sd) for sd in state_dicts]\n",
    "\n",
    "# reshape weights to include \"time\"-dimension as the first dim. \n",
    "layers_of_weights = [torch.stack(x) for x in zip(*weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add functions with names, which add attributes to the graph\n",
    "attribute_functions = {\n",
    "       LINE_COLOR_LIST : black_and_white(layers_of_weights),\n",
    "       LINE_WIDTH_LIST : layerwise_normalized_abs_value(layers_of_weights),\n",
    "    }\n",
    "\n",
    "# create a graph and populate with nodes\n",
    "G = nx.DiGraph()\n",
    "add_neuron_nodes(G, weight_shapes)\n",
    "add_weight_edges_arrays(G, get_layers_of_nodes(G), attribute_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the network with bokeh\n",
    "draw_interactive_mlp_graph(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
