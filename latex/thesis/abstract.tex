\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

The \textbf{Lottery Ticket Hypothesis}~\autocite{LTH} has sparked a novel field of research that concerns itself with sparse neural networks.
One key method in this field, `Iterative Magnitude Pruning' (IMP) is successful in finding the sparse subnetworks that can be trained to high performance, the \textit{Winning Tickets}.
Many aspects of why and how this procedure works and where its success comes from, remain elusive.
One way to learn more about lottery tickets would be to study their network graph.
Since they are usually highly sparse, their graph may contain valuable insights into its functionality.
To learn more about the structure of the sparse `Winning Tickets', experiments inspired by \textcite{BIMT} were conducted.
A dataset with two independent tasks was constructed and a lottery ticket was derived from it with \textit{IMP}.
The question is: Will the winning ticket contain two independent subnetworks, one for each of the independent tasks?